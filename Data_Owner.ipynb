{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "completed-wagner",
   "metadata": {},
   "source": [
    "## Lesson 7\n",
    "\n",
    "### Concept 1\n",
    "Welcome to Lesson 7 of course 3. In this module we will be looking at various steps in the data acquisition and data preparation stage, The aim of this course is to make the students familiar with various steps in the data processing and acquisition stage. By the end of the course (this notebook) the student will learn how to apply preprocessing on a medical dataset example, adding differential privacy to the data and loading the model in pygrid. \n",
    "\n",
    "### Concept 2\n",
    "The instructors of this course are ------\n",
    "\n",
    "### Concept 3\n",
    "In Remote data science the data scientist doesn't have access to the data and hence is unable to understand the data in complete detail and it becomes the responsibility of the data owner to ensure good quality of the dataset. By Quality of the dataset we are referring to quality of annotations, the preprocessing steps in handling the dataset adding differential privacy to make the data more private. \n",
    "\n",
    "### Concept 4\n",
    "The big milestones of this lesson are\n",
    "- Acquisition\n",
    "- Quality check on dataset\n",
    "- Annotation \n",
    "- Converting data to pygrid format\n",
    "- Linking data from multiple sources\n",
    "- Adding Differential Privacy to the metadata of the dataset\n",
    "- Loading data into the node\n",
    "\n",
    "This notebook will focus on these milestones for a single source of dataset for medical images that has binary classification labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09632b5e-6a1a-4d9f-811c-3cc9bc0a22e2",
   "metadata": {},
   "source": [
    "## Pre-Requisites for the notebook\n",
    "\n",
    "It would be easier to setup a virtual environment which can be used to install \n",
    "\n",
    "```\n",
    "conda create -n lab python=3.9\n",
    "```\n",
    "After creating the environment syft can be installed by the following commands sequentially\n",
    "```\n",
    "git clone https://github.com/OpenMined/PySyft && cd PySyft\n",
    "\n",
    "git fetch origin dev\n",
    "\n",
    "git checkout dev\n",
    "\n",
    "cd packages/syft && pip install -e .\n",
    "```\n",
    "Then install other requirements by running this command\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282b02f-d4aa-4364-a7e4-8603bb80e695",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lesbian-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydicom import dcmread\n",
    "import numpy as np\n",
    "import torch\n",
    "from syft.core.adp.entity import Entity\n",
    "import os\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023fccd-bb03-4083-aa20-f9fef1b06798",
   "metadata": {},
   "source": [
    "## Dataset class\n",
    "\n",
    "We need a dataset class that needs to be sent and can be used as a dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nominated-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,root_path,label_file):\n",
    "        self.dataset = pd.read_csv(label_file)\n",
    "        self.root = root_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def to_tensor(self,image):\n",
    "        img = torch.from_numpy(np.ascontiguousarray(image.transpose((2, 0, 1))))\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        filename = self.dataset.loc[idx].at[\"patientId\"]\n",
    "        file_path = os.path.join(root_path, filename)\n",
    "        label = self.dataset.loc[idx].at[\"Target\"]\n",
    "        dicom = dcmread(file_path)\n",
    "        image = dicom.pixel_array\n",
    "        ## Our adp can handle only integer tensors, so cast the tensor to be int\n",
    "        image = self.to_tensor(image).int16() \n",
    "        tensor_image = sy.Tensor(image).private(0,255,entities=Entity(dicom.PatientID))\n",
    "        return tensor_image,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb79b73-5268-47ec-a90f-6f81f8c23d19",
   "metadata": {},
   "source": [
    "## Connect to Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355bd3e-f2b0-4411-ab0b-4c7ca1727dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's login into the domain\n",
    "remote = sy.login(email=\"info@openmined.org\", password=\"changethis\", port=8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551655e6-2850-4c61-9bf4-42e00af2ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset = dataset(root_path,label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9348138-29f5-4142-99d1-291bf37fcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.load_dataset(\n",
    "    assets = {\"chest_xray\":remote_dataset},\n",
    "    name = \"chest xray from NIH\",\n",
    "    description = \"Chest xray dataset of NIH for pneumonia classification\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
